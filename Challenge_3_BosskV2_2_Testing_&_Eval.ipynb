{
  "cells": [
    {
      "cell_type": "code",
      "id": "g4SL3xdgacbB6ANXoLG8CErp",
      "metadata": {
        "tags": [],
        "id": "g4SL3xdgacbB6ANXoLG8CErp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2ee6d1a-bc36-4c2f-9ae9-86f95825c855"
      },
      "source": [
        "# Installing the necessary tools for the job.\n",
        "# pytest is for our unit testing requirement and the google-cloud-aiplatform [evaluation]\n",
        "# library gives us access to the Gen AI Evaluation Service we need for the final requirement.\n",
        "!pip install --upgrade --quiet pytest google-cloud-aiplatform[evaluation] pandas\n",
        "\n",
        "import IPython\n",
        "import time\n",
        "\n",
        "print(\"Libraries installed successfully.\")\n",
        "print(\"Restarting kernel to ensure new libraries are loaded...\")\n",
        "\n",
        "# We need to restart the runtime kernel automatically so that the packages we just installed\n",
        "# are actually recognized and usable by the system immediately.\n",
        "time.sleep(2)\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries installed successfully.\n",
            "Restarting kernel to ensure new libraries are loaded...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'status': 'ok', 'restart': True}"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import vertexai\n",
        "from vertexai.generative_models import GenerativeModel, SafetySetting\n",
        "# Importing EvalTask refrencing the Gen AI Evaluation Service docs\n",
        "from vertexai.preview.evaluation import EvalTask, MetricPromptTemplateExamples\n",
        "# Pulling in the specific evaluation tools directly from the documentation\n",
        "# This EvalTask library is the core component for satisfying Requirement #5 later on.\n",
        "\n",
        "import pytest\n",
        "import pandas as pd\n",
        "import sys\n",
        "import os\n",
        "\n",
        "\n",
        "PROJECT_ID = \"qwiklabs-gcp-03-5dc51bd29ec6\"\n",
        "LOCATION = \"us-central1\"\n",
        "\n",
        "# Initialize Vertex AI SDK\n",
        "print(f\"Initializing Vertex AI for project: {PROJECT_ID} in {LOCATION}\")\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
        "# This basically turns the key in the ignition. It connects the notebook to my specific project\n",
        "\n",
        "# Define the Model we will use for the challenge\n",
        "MODEL_NAME = \"gemini-1.5-flash-001\"\n",
        "model = GenerativeModel(MODEL_NAME)\n",
        "# Instantiating the model object here to act as our default \"engine\".\n",
        "# We might need to override settings for specific functions (like the social media generator),\n",
        "# but this gives us a baseline to work with.\n",
        "\n",
        "print(f\"Environment setup complete. Using model: {MODEL_NAME}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Cr1ACtjmzPp",
        "outputId": "39e92a3a-5e39-4e06-9d23-4c754adaa09b"
      },
      "id": "1Cr1ACtjmzPp",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing Vertex AI for project: qwiklabs-gcp-03-5dc51bd29ec6 in us-central1\n",
            "Environment setup complete. Using model: gemini-1.5-flash-001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import enum\n",
        "from vertexai.generative_models import GenerativeModel, GenerationConfig, SafetySetting\n",
        "\n",
        "# Re-defining MODEL_NAME locally to ensure this cell runs independently if needed\n",
        "MODEL_NAME = \"gemini-2.5-flash\"\n",
        "\n",
        "class DepartmentCategory(enum.Enum):\n",
        "    EMPLOYMENT = \"Employment\"\n",
        "    GENERAL = \"General Information\"\n",
        "    EMERGENCY = \"Emergency Services\"\n",
        "    TAX = \"Tax Related\"\n",
        "# This is my Strict Typing strategy. By using a Python Enum instead of raw strings,\n",
        "# I ensure I can't accidentally type \"Emploiment\" later in the tests and break the logic.\n",
        "# It makes the code much more robust.\n",
        "\n",
        "def classify_inquiry(user_question: str) -> str:\n",
        "    \"\"\"\n",
        "    Classifies a citizen inquiry into a specific department category using Gemini.\n",
        "    \"\"\"\n",
        "\n",
        "    # System instructions guide the model's behavior globally\n",
        "    system_instruction = f\"\"\"\n",
        "    You are an intelligent classification system for the Aurora Bay municipal government.\n",
        "    Your job is to categorize user inquiries into exactly one of these four categories:\n",
        "\n",
        "    1. {DepartmentCategory.EMPLOYMENT.value}\n",
        "    2. {DepartmentCategory.GENERAL.value}\n",
        "    3. {DepartmentCategory.EMERGENCY.value}\n",
        "    4. {DepartmentCategory.TAX.value}\n",
        "\n",
        "    Output Rules:\n",
        "    - Respond ONLY with the exact category name.\n",
        "    - Do not add punctuation or filler.\n",
        "    \"\"\"\n",
        "    # Moving the rules into 'system_instruction' is cleaner than stuffing them into the prompt.\n",
        "    # It separates the business logic from the user input\n",
        "\n",
        "    try:\n",
        "        model = GenerativeModel(\n",
        "            MODEL_NAME,\n",
        "            system_instruction=[system_instruction]\n",
        "        )\n",
        "        # FIX: Removed max_output_tokens parameter completely.\n",
        "        # This allows the model to use its default maximum (usually 8k+)\n",
        "        # preventing the \"MAX_TOKENS\" error during reasoning.\n",
        "        config = GenerationConfig(\n",
        "            temperature=0.0,\n",
        "            candidate_count=1\n",
        "        )\\\n",
        "        # I set temperature to 0.0 because classification needs to be deterministic, not creative.\n",
        "        # Crucially, I removed the 'max_output_tokens' limit here. We found that 2.5-flash\n",
        "        # uses \"hidden thought tokens\" that were crashing the model when I set tight limits.\n",
        "\n",
        "        # Explicitly allow content to ensure \"Fire\" doesn't trigger safety blocks\n",
        "        safety_config = [\n",
        "            SafetySetting(\n",
        "                category=SafetySetting.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,\n",
        "                threshold=SafetySetting.HarmBlockThreshold.BLOCK_ONLY_HIGH\n",
        "            ),\n",
        "            SafetySetting(\n",
        "                category=SafetySetting.HarmCategory.HARM_CATEGORY_HARASSMENT,\n",
        "                threshold=SafetySetting.HarmBlockThreshold.BLOCK_ONLY_HIGH\n",
        "            ),\n",
        "        ]\n",
        "        # This is a necessary safeguard. Without it, legitimate queries about \"fires\" or\n",
        "        # \"emergencies\" might trigger the default safety filters and return nothing.\n",
        "\n",
        "        response = model.generate_content(\n",
        "            user_question,\n",
        "            generation_config=config,\n",
        "            safety_settings=safety_config\n",
        "        )\n",
        "\n",
        "        return response.text.strip()\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "# --- Verification ---\n",
        "print(\"--- Testing Classification Function (No Token Limit) ---\")\n",
        "test_questions = [\n",
        "    \"Where can I find the job application for the road crew?\",\n",
        "    \"My house is on fire!\",\n",
        "    \"When are property taxes due?\",\n",
        "    \"What time does the library close?\"\n",
        "]\n",
        "\n",
        "for q in test_questions:\n",
        "    category = classify_inquiry(q)\n",
        "    print(f\"Q: {q}\\n -> Category: {category}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qVcHFjEpE5z",
        "outputId": "e8d7dd96-1d8e-477c-f977-464f5aa6dbad"
      },
      "id": "2qVcHFjEpE5z",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Testing Classification Function (No Token Limit) ---\n",
            "Q: Where can I find the job application for the road crew?\n",
            " -> Category: Employment\n",
            "\n",
            "Q: My house is on fire!\n",
            " -> Category: Emergency Services\n",
            "\n",
            "Q: When are property taxes due?\n",
            " -> Category: Tax Related\n",
            "\n",
            "Q: What time does the library close?\n",
            " -> Category: General Information\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Segment 3: Social Media Generator\n",
        "\n",
        "class SocialPlatform(enum.Enum):\n",
        "    TWITTER = \"Twitter (X)\"\n",
        "    FACEBOOK = \"Facebook\"\n",
        "    LINKEDIN = \"LinkedIn\"\n",
        "# Using Enum again here. It ensures I don't accidentally pass an unsupported platform string\n",
        "# and allows me to map specific rules (like character limits) to these exact values later.\n",
        "\n",
        "def generate_social_post(topic: str, platform: SocialPlatform = SocialPlatform.TWITTER) -> str:\n",
        "    \"\"\"\n",
        "    Generates a government social media post for a specific topic and platform.\n",
        "\n",
        "    Args:\n",
        "        topic: The subject of the post (e.g., \"School closing due to snow\").\n",
        "        platform: The target social media platform (defaults to Twitter).\n",
        "\n",
        "    Returns:\n",
        "        str: The generated post text.\n",
        "    \"\"\"\n",
        "\n",
        "    # System instructions establish the Persona\n",
        "    system_instruction = f\"\"\"\n",
        "    You are the Communications Director for Aurora Bay.\n",
        "    Your goal is to write clear, authoritative, yet empathetic social media posts.\n",
        "\n",
        "    Platform Rules:\n",
        "    - {SocialPlatform.TWITTER.value}: Under 280 chars. Concise. Use 2-3 hashtags.\n",
        "    - {SocialPlatform.FACEBOOK.value}: Can be longer (3-5 sentences). Warm tone. Use 1-2 hashtags.\n",
        "    - {SocialPlatform.LINKEDIN.value}: Professional tone. Focus on community impact.\n",
        "\n",
        "    General Rules:\n",
        "    - Never invent facts. If details are missing, use brackets like [Date] or [Time].\n",
        "    - Always include the official town hashtag: #AuroraBay\n",
        "    \"\"\"\n",
        "    # I'm baking the \"Persona\" and the specific rules directly into the system instructions.\n",
        "    # This aligns with the prompt engineering best practices from the slides—defining the role up front.\n",
        "\n",
        "    try:\n",
        "        # Initialize model with the specific persona\n",
        "        social_model = GenerativeModel(\n",
        "            MODEL_NAME,\n",
        "            system_instruction=[system_instruction]\n",
        "        )\n",
        "\n",
        "        # Config: Higher temperature for creativity\n",
        "        # We removed max_output_tokens to avoid cutting off longer Facebook posts\n",
        "        config = GenerationConfig(\n",
        "            temperature=0.7,\n",
        "            candidate_count=1\n",
        "        )\n",
        "        # This is a key difference from the Classification function. I bumped temperature to 0.7\n",
        "        # because social media needs to sound human and creative, not robotic.\n",
        "        # I also removed the token limit we struggled with earlier so it has room to write full posts. Issues kept occuring on breaking on this end\n",
        "\n",
        "        prompt = f\"Write a {platform.value} post about: {topic}\"\n",
        "\n",
        "        response = social_model.generate_content(\n",
        "            prompt,\n",
        "            generation_config=config\n",
        "        )\n",
        "\n",
        "        return response.text.strip()\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Error generating post: {str(e)}\"\n",
        "\n",
        "# --- Verification ---\n",
        "print(\"--- Testing Social Media Generator ---\")\n",
        "topics = [\n",
        "    (\"Twitter (X)\", \"Heavy snow emergency declared. Parking ban in effect.\"),\n",
        "    (\"Facebook\", \"Annual 4th of July parade details.\"),\n",
        "]\n",
        "\n",
        "for platform_name, topic in topics:\n",
        "    # Map string to Enum for testing\n",
        "    platform_enum = SocialPlatform(platform_name)\n",
        "    post = generate_social_post(topic, platform=platform_enum)\n",
        "\n",
        "    print(f\"\\n[{platform_name}] Topic: {topic}\")\n",
        "    print(\"-\" * 40)\n",
        "    print(post)\n",
        "    print(\"-\" * 40)\n",
        "# Quick loop to verify it actually adapts the tone. I want to see a short Tweet\n",
        "# and a longer Facebook post to confirm the system instructions are working."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26LKvQMopMuF",
        "outputId": "c5bbb4bc-0ee7-4657-ad1a-64ac09161a03"
      },
      "id": "26LKvQMopMuF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Testing Social Media Generator ---\n",
            "\n",
            "[Twitter (X)] Topic: Heavy snow emergency declared. Parking ban in effect.\n",
            "----------------------------------------\n",
            "**Twitter (X):**\n",
            "\n",
            "Heavy snow emergency declared for Aurora Bay. A parking ban is now in effect. Please move vehicles to help plows clear streets safely. Stay warm & safe! #AuroraBay #SnowEmergency #ParkingBan\n",
            "----------------------------------------\n",
            "\n",
            "[Facebook] Topic: Annual 4th of July parade details.\n",
            "----------------------------------------\n",
            "Here's a Facebook post about the Annual 4th of July parade details:\n",
            "\n",
            "Get ready to celebrate, Aurora Bay! Our much-anticipated Annual 4th of July Parade is just around the corner, and we can't wait to see our community come together in patriotic spirit. Join us on [Date] at [Time] as the parade kicks off from [Starting Location] and winds its way through [Route Details], showcasing local organizations, festive floats, and plenty of red, white, and blue! Bring your family, friends, and your biggest cheers to celebrate Independence Day with your neighbors. It's going to be a fantastic day of community and celebration! #AuroraBay #FourthOfJulyParade\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "current_project = os.environ.get(\"GOOGLE_CLOUD_PROJECT\") or PROJECT_ID\n",
        "current_location = LOCATION\n",
        "# Sticking with gemini-2.5-flash since we confirmed it exists in the environment.\n",
        "MODEL_NAME = \"gemini-2.5-flash\"\n",
        "\n",
        "test_file_content = f\"\"\"\n",
        "import pytest\n",
        "import enum\n",
        "import vertexai\n",
        "from vertexai.generative_models import GenerativeModel, GenerationConfig, SafetySetting\n",
        "\n",
        "# --- SETUP ---\n",
        "PROJECT_ID = \"{current_project}\"\n",
        "LOCATION = \"{current_location}\"\n",
        "MODEL_NAME = \"{MODEL_NAME}\"\n",
        "\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
        "\n",
        "# --- DEFINITIONS ---\n",
        "\n",
        "class DepartmentCategory(enum.Enum):\n",
        "    EMPLOYMENT = \"Employment\"\n",
        "    GENERAL = \"General Information\"\n",
        "    EMERGENCY = \"Emergency Services\"\n",
        "    TAX = \"Tax Related\"\n",
        "\n",
        "class SocialPlatform(enum.Enum):\n",
        "    TWITTER = \"Twitter (X)\"\n",
        "    FACEBOOK = \"Facebook\"\n",
        "\n",
        "# I'm defining explicit Safety Settings here to prevent the model from blocking\n",
        "# legitimate queries about \"fire\" or \"emergencies\" during testing.\n",
        "SAFETY_CONFIG = [\n",
        "    SafetySetting(\n",
        "        category=SafetySetting.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,\n",
        "        threshold=SafetySetting.HarmBlockThreshold.BLOCK_ONLY_HIGH\n",
        "    ),\n",
        "    SafetySetting(\n",
        "        category=SafetySetting.HarmCategory.HARM_CATEGORY_HARASSMENT,\n",
        "        threshold=SafetySetting.HarmBlockThreshold.BLOCK_ONLY_HIGH\n",
        "    ),\n",
        "]\n",
        "\n",
        "def classify_inquiry(user_question):\n",
        "    model = GenerativeModel(MODEL_NAME)\n",
        "    prompt = f'''\n",
        "    Classify into exactly one category:\n",
        "    {{DepartmentCategory.EMPLOYMENT.value}}, {{DepartmentCategory.GENERAL.value}},\n",
        "    {{DepartmentCategory.EMERGENCY.value}}, {{DepartmentCategory.TAX.value}}.\n",
        "    Input: {{user_question}}\n",
        "    Output (Category Name Only):\n",
        "    '''\n",
        "    # Classification is straightforward, so I'm keeping the config simple.\n",
        "    response = model.generate_content(\n",
        "        prompt,\n",
        "        generation_config=GenerationConfig(temperature=0.0, max_output_tokens=100),\n",
        "        safety_settings=SAFETY_CONFIG\n",
        "    )\n",
        "    return response.text.strip()\n",
        "\n",
        "def generate_social_post(topic, platform):\n",
        "    model = GenerativeModel(MODEL_NAME)\n",
        "\n",
        "    # STRATEGY: MINIMALIST PROMPT (The \"Fix\")\n",
        "    # Through trial and error, I found that complex prompts caused the 2.5-flash model\n",
        "    # to \"over-think\" and hit token limits before writing the actual post.\n",
        "    # By stripping out the persona and examples, I force it to be direct.\n",
        "    prompt = f\"Write a {{platform.value}} post about: {{topic}}. Keep it professional, under 280 chars, and include one hashtag.\"\n",
        "\n",
        "    # I'm requesting a huge token limit (8192) to try and override any low defaults\n",
        "    # the environment might be enforcing.\n",
        "    response = model.generate_content(\n",
        "        prompt,\n",
        "        generation_config=GenerationConfig(\n",
        "            temperature=0.7,\n",
        "            max_output_tokens=8192\n",
        "        ),\n",
        "        safety_settings=SAFETY_CONFIG\n",
        "    )\n",
        "    return response.text.strip()\n",
        "\n",
        "# --- TESTS ---\n",
        "\n",
        "def test_classification_emergency():\n",
        "    # Verifying that critical keywords like \"fire\" route correctly to Emergency.\n",
        "    question = \"There is a fire at the main street library!\"\n",
        "    result = classify_inquiry(question)\n",
        "    assert DepartmentCategory.EMERGENCY.value in result\n",
        "\n",
        "def test_classification_tax():\n",
        "    question = \"When is the property tax deadline?\"\n",
        "    result = classify_inquiry(question)\n",
        "    assert DepartmentCategory.TAX.value in result\n",
        "\n",
        "def test_twitter_length():\n",
        "    topic = \"Trash collection delayed\"\n",
        "    post = generate_social_post(topic, SocialPlatform.TWITTER)\n",
        "    # Adding a debug print so if this fails, I can see exactly what the model output.\n",
        "    print(f\"DEBUG OUTPUT: {{post}}\")\n",
        "    # Checking for a valid length: not too short (empty) and not too long (over limit).\n",
        "    assert len(post) > 10\n",
        "    assert len(post) < 400\n",
        "\n",
        "def test_social_content_relevance():\n",
        "    topic = \"Fourth of July Parade\"\n",
        "    post = generate_social_post(topic, SocialPlatform.FACEBOOK)\n",
        "    # Ensuring the model actually writes about the requested topic.\n",
        "    assert \"July\" in post or \"Parade\" in post or \"4th\" in post\n",
        "\"\"\"\n",
        "\n",
        "# Writing this content to a physical file so pytest can run it independently.\n",
        "with open(\"test_challenge.py\", \"w\") as f:\n",
        "    f.write(test_file_content)\n",
        "\n",
        "print(f\"Updated 'test_challenge.py' with Minimalist Prompt Strategy.\")"
      ],
      "metadata": {
        "id": "BdGmwVU38yTT"
      },
      "id": "BdGmwVU38yTT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Segment 5 (Fix): Evaluation using Gemini 2.5 with Robust Config\n",
        "import pandas as pd\n",
        "from vertexai.preview.evaluation import EvalTask\n",
        "from vertexai.generative_models import GenerativeModel, GenerationConfig, SafetySetting\n",
        "\n",
        "print(\"Setting up Evaluation Task (Gemini 2.5)...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# 1. Configuration to prevent crashes\n",
        "# We apply these settings globally to the model instance\n",
        "safe_config = [\n",
        "    SafetySetting(\n",
        "        category=SafetySetting.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,\n",
        "        threshold=SafetySetting.HarmBlockThreshold.BLOCK_ONLY_HIGH\n",
        "    ),\n",
        "    SafetySetting(\n",
        "        category=SafetySetting.HarmCategory.HARM_CATEGORY_HARASSMENT,\n",
        "        threshold=SafetySetting.HarmBlockThreshold.BLOCK_ONLY_HIGH\n",
        "    ),\n",
        "]\n",
        "# I'm explicitly defining permissive safety settings here to ensure the Evaluation service\n",
        "# doesn't mistakenly flag our \"Emergency\" or \"Fire\" test cases as dangerous content.\n",
        "\n",
        "gen_config = GenerationConfig(\n",
        "    temperature=0.7,\n",
        "    max_output_tokens=8192 # Force high limit to accommodate \"Thinking\" tokens\n",
        ")\n",
        "# This is the critical fix from our troubleshooting. By forcing the max tokens to 8192,\n",
        "# I am giving the Gemini 2.5 model enough budget to do its internal reasoning/thinking\n",
        "# without crashing before it writes the actual social media post.\n",
        "\n",
        "# 2. Initialize Model with Config\n",
        "# We use the version we KNOW exists in your lab\n",
        "EVAL_MODEL = GenerativeModel(\n",
        "    \"gemini-2.5-flash\",\n",
        "    generation_config=gen_config,\n",
        "    safety_settings=safe_config\n",
        ")\n",
        "# Initializing the model object with the config *attached*. The EvalTask will use this\n",
        "# exact object, so it inherits our safety bypasses and token fixes automatically.\n",
        "\n",
        "# 3. Define Dataset\n",
        "eval_dataset = pd.DataFrame({\n",
        "    \"topic\": [\n",
        "        \"School closed due to heavy snow\",\n",
        "        \"Town Hall closed for Thanksgiving\",\n",
        "        \"Trash collection delayed by one day\"\n",
        "    ],\n",
        "    \"reference\": [\n",
        "        \"ALERT: All Aurora Bay schools are closed today due to snow. Stay safe! #AuroraBay\",\n",
        "        \"Town Hall is closed Thursday & Friday for Thanksgiving. Emergency services remain available. #AuroraBay\",\n",
        "        \"NOTICE: Trash collection is delayed one day this week due to the holiday. #AuroraBay\"\n",
        "    ]\n",
        "})\n",
        "# Creating a small \"Golden Dataset\"  using pandas. The reference column serves\n",
        "# as the Ground Truth that the rouge metric will compare the model's output against.\n",
        "\n",
        "metrics = [\"rouge_l\", \"coherence\"]\n",
        "# Selecting my metrics:\n",
        "# - 'rouge_l' is a Computed Metric to check if the keywords match our reference.\n",
        "# - 'coherence' is a Model-Based Metric where a 'Judge' LLM rates the flow of the text.\n",
        "\n",
        "# 4. Define Prompt Templates\n",
        "# We use the Few-Shot strategy that proved stable in peer tests\n",
        "prompt_templates = {\n",
        "    \"Zero-Shot\": \"Write a Twitter post for Aurora Bay about: {topic}\",\n",
        "\n",
        "    \"Few-Shot\": \"\"\"\n",
        "    You are the social media manager for Aurora Bay.\n",
        "    Write a Twitter post about: {topic}\n",
        "\n",
        "    EXAMPLE:\n",
        "    Input: School closed due to snow\n",
        "    Output: ALERT: All Aurora Bay schools are closed today due to snow. Stay safe! #AuroraBay\n",
        "\n",
        "    Input: {topic}\n",
        "    Output:\n",
        "    \"\"\"\n",
        "}\n",
        "# This satisfies Requirement #5\n",
        "# I'm testing if giving an example (Few-Shot) actually improves performance over just asking (Zero-Shot).\n",
        "\n",
        "results = {}\n",
        "\n",
        "# 5. Run Evaluation\n",
        "for strategy_name, template in prompt_templates.items():\n",
        "    print(f\"\\nEvaluating Strategy: {strategy_name}...\")\n",
        "\n",
        "    eval_task = EvalTask(\n",
        "        dataset=eval_dataset,\n",
        "        metrics=metrics,\n",
        "        experiment=f\"aurora-prompt-eval-{strategy_name.lower()}\"\n",
        "    )\n",
        "\n",
        "    # Passing the pre-configured model ensures settings are respected\n",
        "    eval_result = eval_task.evaluate(\n",
        "        model=EVAL_MODEL,\n",
        "        prompt_template=template,\n",
        "    )\n",
        "\n",
        "    results[strategy_name] = eval_result.summary_metrics\n",
        "    # Storing the results so I can print a nice comparison table at the end.\n",
        "\n",
        "# 6. Display Results\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"PROMPT COMPARISON RESULTS\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"{'Metric':<15} {'Zero-Shot':<15} {'Few-Shot':<15}\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "def get_metric(stats, metric_name):\n",
        "    return stats.get(f\"{metric_name}/mean\", 0.0)\n",
        "\n",
        "for metric in metrics:\n",
        "    score_zero = get_metric(results['Zero-Shot'], metric)\n",
        "    score_few = get_metric(results['Few-Shot'], metric)\n",
        "\n",
        "    winner_zero = \"*\" if score_zero > score_few else \"\"\n",
        "    winner_few = \"*\" if score_few > score_zero else \"\"\n",
        "\n",
        "    print(f\"{metric:<15} {score_zero:.4f}{winner_zero:<10} {score_few:.4f}{winner_few}\")\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"Evaluation Complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 902
        },
        "id": "tSgfidicyjKk",
        "outputId": "fd492336-3fb1-4626-8361-32f3d8c3b123"
      },
      "id": "tSgfidicyjKk",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up Evaluation Task (Gemini 2.5)...\n",
            "============================================================\n",
            "\n",
            "Evaluating Strategy: Zero-Shot...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        \n",
              "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
              "    <style>\n",
              "      .view-vertex-resource,\n",
              "      .view-vertex-resource:hover,\n",
              "      .view-vertex-resource:visited {\n",
              "        position: relative;\n",
              "        display: inline-flex;\n",
              "        flex-direction: row;\n",
              "        height: 32px;\n",
              "        padding: 0 12px;\n",
              "          margin: 4px 18px;\n",
              "        gap: 4px;\n",
              "        border-radius: 4px;\n",
              "\n",
              "        align-items: center;\n",
              "        justify-content: center;\n",
              "        background-color: rgb(255, 255, 255);\n",
              "        color: rgb(51, 103, 214);\n",
              "\n",
              "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
              "        font-size: 13px;\n",
              "        font-weight: 500;\n",
              "        text-transform: uppercase;\n",
              "        text-decoration: none !important;\n",
              "\n",
              "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
              "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
              "      }\n",
              "      .view-vertex-resource:active {\n",
              "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
              "      }\n",
              "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
              "        position: absolute;\n",
              "        top: 0;\n",
              "        bottom: 0;\n",
              "        left: 0;\n",
              "        right: 0;\n",
              "        border-radius: 4px;\n",
              "        pointer-events: none;\n",
              "\n",
              "        content: '';\n",
              "        background-color: rgb(51, 103, 214);\n",
              "        opacity: 0.12;\n",
              "      }\n",
              "      .view-vertex-icon {\n",
              "        font-size: 18px;\n",
              "      }\n",
              "    </style>\n",
              "  \n",
              "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-91b2a794-349d-4a12-b90e-9c547acf3a64\" href=\"#view-view-vertex-resource-91b2a794-349d-4a12-b90e-9c547acf3a64\">\n",
              "          <span class=\"material-icons view-vertex-icon\">science</span>\n",
              "          <span>View Experiment</span>\n",
              "        </a>\n",
              "        \n",
              "        <script>\n",
              "          (function () {\n",
              "            const link = document.getElementById('view-vertex-resource-91b2a794-349d-4a12-b90e-9c547acf3a64');\n",
              "            link.addEventListener('click', (e) => {\n",
              "              if (window.google?.colab?.openUrl) {\n",
              "                window.google.colab.openUrl('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/aurora-prompt-eval-zero-shot/runs?project=qwiklabs-gcp-03-5dc51bd29ec6');\n",
              "              } else {\n",
              "                window.open('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/aurora-prompt-eval-zero-shot/runs?project=qwiklabs-gcp-03-5dc51bd29ec6', '_blank');\n",
              "              }\n",
              "              e.stopPropagation();\n",
              "              e.preventDefault();\n",
              "            });\n",
              "          })();\n",
              "        </script>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        \n",
              "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
              "    <style>\n",
              "      .view-vertex-resource,\n",
              "      .view-vertex-resource:hover,\n",
              "      .view-vertex-resource:visited {\n",
              "        position: relative;\n",
              "        display: inline-flex;\n",
              "        flex-direction: row;\n",
              "        height: 32px;\n",
              "        padding: 0 12px;\n",
              "          margin: 4px 18px;\n",
              "        gap: 4px;\n",
              "        border-radius: 4px;\n",
              "\n",
              "        align-items: center;\n",
              "        justify-content: center;\n",
              "        background-color: rgb(255, 255, 255);\n",
              "        color: rgb(51, 103, 214);\n",
              "\n",
              "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
              "        font-size: 13px;\n",
              "        font-weight: 500;\n",
              "        text-transform: uppercase;\n",
              "        text-decoration: none !important;\n",
              "\n",
              "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
              "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
              "      }\n",
              "      .view-vertex-resource:active {\n",
              "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
              "      }\n",
              "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
              "        position: absolute;\n",
              "        top: 0;\n",
              "        bottom: 0;\n",
              "        left: 0;\n",
              "        right: 0;\n",
              "        border-radius: 4px;\n",
              "        pointer-events: none;\n",
              "\n",
              "        content: '';\n",
              "        background-color: rgb(51, 103, 214);\n",
              "        opacity: 0.12;\n",
              "      }\n",
              "      .view-vertex-icon {\n",
              "        font-size: 18px;\n",
              "      }\n",
              "    </style>\n",
              "  \n",
              "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-f24fbfaa-cc91-48ff-9b13-9f21a42d66b4\" href=\"#view-view-vertex-resource-f24fbfaa-cc91-48ff-9b13-9f21a42d66b4\">\n",
              "          <span class=\"material-icons view-vertex-icon\">science</span>\n",
              "          <span>View Experiment Run</span>\n",
              "        </a>\n",
              "        \n",
              "        <script>\n",
              "          (function () {\n",
              "            const link = document.getElementById('view-vertex-resource-f24fbfaa-cc91-48ff-9b13-9f21a42d66b4');\n",
              "            link.addEventListener('click', (e) => {\n",
              "              if (window.google?.colab?.openUrl) {\n",
              "                window.google.colab.openUrl('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/aurora-prompt-eval-zero-shot/runs/aurora-prompt-eval-zero-shot-bf0ff0a6-a2d6-41b6-9892-b08e365319c1?project=qwiklabs-gcp-03-5dc51bd29ec6');\n",
              "              } else {\n",
              "                window.open('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/aurora-prompt-eval-zero-shot/runs/aurora-prompt-eval-zero-shot-bf0ff0a6-a2d6-41b6-9892-b08e365319c1?project=qwiklabs-gcp-03-5dc51bd29ec6', '_blank');\n",
              "              }\n",
              "              e.stopPropagation();\n",
              "              e.preventDefault();\n",
              "            });\n",
              "          })();\n",
              "        </script>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:vertexai.preview.evaluation.eval_task:Logging Eval experiment evaluation metadata: {'prompt_template': 'Write a Twitter post for Aurora Bay about: {topic}', 'model_name': 'publishers/google/models/gemini-2.5-flash'}\n",
            "INFO:vertexai.preview.evaluation._evaluation:Assembling prompts from the `prompt_template`. The `prompt` column in the `EvalResult.metrics_table` has the assembled prompts used for model response generation.\n",
            "INFO:vertexai.preview.evaluation._pre_eval_utils:Generating a total of 3 responses from Gemini model gemini-2.5-flash.\n",
            "100%|██████████| 3/3 [00:10<00:00,  3.37s/it]\n",
            "INFO:vertexai.preview.evaluation._pre_eval_utils:All 3 responses are successfully generated from model.\n",
            "INFO:vertexai.preview.evaluation._evaluation:Multithreaded Batch Inference took: 10.122205472000132 seconds.\n",
            "INFO:vertexai.preview.evaluation._evaluation:Computing metrics with a total of 6 Vertex Gen AI Evaluation Service API requests.\n",
            "100%|██████████| 6/6 [00:09<00:00,  1.53s/it]\n",
            "INFO:vertexai.preview.evaluation._evaluation:All 6 metric requests are successfully computed.\n",
            "INFO:vertexai.preview.evaluation._evaluation:Evaluation Took:9.215586084000279 seconds\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        \n",
              "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
              "    <style>\n",
              "      .view-vertex-resource,\n",
              "      .view-vertex-resource:hover,\n",
              "      .view-vertex-resource:visited {\n",
              "        position: relative;\n",
              "        display: inline-flex;\n",
              "        flex-direction: row;\n",
              "        height: 32px;\n",
              "        padding: 0 12px;\n",
              "          margin: 4px 18px;\n",
              "        gap: 4px;\n",
              "        border-radius: 4px;\n",
              "\n",
              "        align-items: center;\n",
              "        justify-content: center;\n",
              "        background-color: rgb(255, 255, 255);\n",
              "        color: rgb(51, 103, 214);\n",
              "\n",
              "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
              "        font-size: 13px;\n",
              "        font-weight: 500;\n",
              "        text-transform: uppercase;\n",
              "        text-decoration: none !important;\n",
              "\n",
              "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
              "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
              "      }\n",
              "      .view-vertex-resource:active {\n",
              "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
              "      }\n",
              "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
              "        position: absolute;\n",
              "        top: 0;\n",
              "        bottom: 0;\n",
              "        left: 0;\n",
              "        right: 0;\n",
              "        border-radius: 4px;\n",
              "        pointer-events: none;\n",
              "\n",
              "        content: '';\n",
              "        background-color: rgb(51, 103, 214);\n",
              "        opacity: 0.12;\n",
              "      }\n",
              "      .view-vertex-icon {\n",
              "        font-size: 18px;\n",
              "      }\n",
              "    </style>\n",
              "  \n",
              "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-11601fee-62be-405a-b543-628b8b493d2e\" href=\"#view-view-vertex-resource-11601fee-62be-405a-b543-628b8b493d2e\">\n",
              "          <span class=\"material-icons view-vertex-icon\">bar_chart</span>\n",
              "          <span>View evaluation results</span>\n",
              "        </a>\n",
              "        \n",
              "        <script>\n",
              "          (function () {\n",
              "            const link = document.getElementById('view-vertex-resource-11601fee-62be-405a-b543-628b8b493d2e');\n",
              "            link.addEventListener('click', (e) => {\n",
              "              if (window.google?.colab?.openUrl) {\n",
              "                window.google.colab.openUrl('https://cloud.google.com/vertex-ai/generative-ai/docs/models/view-evaluation');\n",
              "              } else {\n",
              "                window.open('https://cloud.google.com/vertex-ai/generative-ai/docs/models/view-evaluation', '_blank');\n",
              "              }\n",
              "              e.stopPropagation();\n",
              "              e.preventDefault();\n",
              "            });\n",
              "          })();\n",
              "        </script>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating Strategy: Few-Shot...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        \n",
              "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
              "    <style>\n",
              "      .view-vertex-resource,\n",
              "      .view-vertex-resource:hover,\n",
              "      .view-vertex-resource:visited {\n",
              "        position: relative;\n",
              "        display: inline-flex;\n",
              "        flex-direction: row;\n",
              "        height: 32px;\n",
              "        padding: 0 12px;\n",
              "          margin: 4px 18px;\n",
              "        gap: 4px;\n",
              "        border-radius: 4px;\n",
              "\n",
              "        align-items: center;\n",
              "        justify-content: center;\n",
              "        background-color: rgb(255, 255, 255);\n",
              "        color: rgb(51, 103, 214);\n",
              "\n",
              "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
              "        font-size: 13px;\n",
              "        font-weight: 500;\n",
              "        text-transform: uppercase;\n",
              "        text-decoration: none !important;\n",
              "\n",
              "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
              "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
              "      }\n",
              "      .view-vertex-resource:active {\n",
              "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
              "      }\n",
              "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
              "        position: absolute;\n",
              "        top: 0;\n",
              "        bottom: 0;\n",
              "        left: 0;\n",
              "        right: 0;\n",
              "        border-radius: 4px;\n",
              "        pointer-events: none;\n",
              "\n",
              "        content: '';\n",
              "        background-color: rgb(51, 103, 214);\n",
              "        opacity: 0.12;\n",
              "      }\n",
              "      .view-vertex-icon {\n",
              "        font-size: 18px;\n",
              "      }\n",
              "    </style>\n",
              "  \n",
              "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-af524b1d-cc99-4d1f-aadd-8f65e1138ae9\" href=\"#view-view-vertex-resource-af524b1d-cc99-4d1f-aadd-8f65e1138ae9\">\n",
              "          <span class=\"material-icons view-vertex-icon\">science</span>\n",
              "          <span>View Experiment</span>\n",
              "        </a>\n",
              "        \n",
              "        <script>\n",
              "          (function () {\n",
              "            const link = document.getElementById('view-vertex-resource-af524b1d-cc99-4d1f-aadd-8f65e1138ae9');\n",
              "            link.addEventListener('click', (e) => {\n",
              "              if (window.google?.colab?.openUrl) {\n",
              "                window.google.colab.openUrl('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/aurora-prompt-eval-few-shot/runs?project=qwiklabs-gcp-03-5dc51bd29ec6');\n",
              "              } else {\n",
              "                window.open('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/aurora-prompt-eval-few-shot/runs?project=qwiklabs-gcp-03-5dc51bd29ec6', '_blank');\n",
              "              }\n",
              "              e.stopPropagation();\n",
              "              e.preventDefault();\n",
              "            });\n",
              "          })();\n",
              "        </script>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        \n",
              "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
              "    <style>\n",
              "      .view-vertex-resource,\n",
              "      .view-vertex-resource:hover,\n",
              "      .view-vertex-resource:visited {\n",
              "        position: relative;\n",
              "        display: inline-flex;\n",
              "        flex-direction: row;\n",
              "        height: 32px;\n",
              "        padding: 0 12px;\n",
              "          margin: 4px 18px;\n",
              "        gap: 4px;\n",
              "        border-radius: 4px;\n",
              "\n",
              "        align-items: center;\n",
              "        justify-content: center;\n",
              "        background-color: rgb(255, 255, 255);\n",
              "        color: rgb(51, 103, 214);\n",
              "\n",
              "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
              "        font-size: 13px;\n",
              "        font-weight: 500;\n",
              "        text-transform: uppercase;\n",
              "        text-decoration: none !important;\n",
              "\n",
              "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
              "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
              "      }\n",
              "      .view-vertex-resource:active {\n",
              "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
              "      }\n",
              "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
              "        position: absolute;\n",
              "        top: 0;\n",
              "        bottom: 0;\n",
              "        left: 0;\n",
              "        right: 0;\n",
              "        border-radius: 4px;\n",
              "        pointer-events: none;\n",
              "\n",
              "        content: '';\n",
              "        background-color: rgb(51, 103, 214);\n",
              "        opacity: 0.12;\n",
              "      }\n",
              "      .view-vertex-icon {\n",
              "        font-size: 18px;\n",
              "      }\n",
              "    </style>\n",
              "  \n",
              "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-ff4543a4-d447-4c90-a317-734e7a683fa9\" href=\"#view-view-vertex-resource-ff4543a4-d447-4c90-a317-734e7a683fa9\">\n",
              "          <span class=\"material-icons view-vertex-icon\">science</span>\n",
              "          <span>View Experiment Run</span>\n",
              "        </a>\n",
              "        \n",
              "        <script>\n",
              "          (function () {\n",
              "            const link = document.getElementById('view-vertex-resource-ff4543a4-d447-4c90-a317-734e7a683fa9');\n",
              "            link.addEventListener('click', (e) => {\n",
              "              if (window.google?.colab?.openUrl) {\n",
              "                window.google.colab.openUrl('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/aurora-prompt-eval-few-shot/runs/aurora-prompt-eval-few-shot-e7db5b63-f909-4f1a-b6b2-2c5618f2ddff?project=qwiklabs-gcp-03-5dc51bd29ec6');\n",
              "              } else {\n",
              "                window.open('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/aurora-prompt-eval-few-shot/runs/aurora-prompt-eval-few-shot-e7db5b63-f909-4f1a-b6b2-2c5618f2ddff?project=qwiklabs-gcp-03-5dc51bd29ec6', '_blank');\n",
              "              }\n",
              "              e.stopPropagation();\n",
              "              e.preventDefault();\n",
              "            });\n",
              "          })();\n",
              "        </script>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:vertexai.preview.evaluation.eval_task:Logging Eval experiment evaluation metadata: {'prompt_template': '\\n    You are the social media manager for Aurora Bay.\\n    Write a Twitter post about: {topic}\\n    \\n    EXAMPLE:\\n    Input: School closed due to snow\\n    Output: ALERT: All Aurora Bay schools are closed today due to snow. Stay safe! #AuroraBay\\n    \\n    Input: {topic}\\n    Output:\\n    ', 'model_name': 'publishers/google/models/gemini-2.5-flash'}\n",
            "INFO:vertexai.preview.evaluation._evaluation:Assembling prompts from the `prompt_template`. The `prompt` column in the `EvalResult.metrics_table` has the assembled prompts used for model response generation.\n",
            "INFO:vertexai.preview.evaluation._pre_eval_utils:Generating a total of 3 responses from Gemini model gemini-2.5-flash.\n",
            "100%|██████████| 3/3 [00:03<00:00,  1.31s/it]\n",
            "INFO:vertexai.preview.evaluation._pre_eval_utils:All 3 responses are successfully generated from model.\n",
            "INFO:vertexai.preview.evaluation._evaluation:Multithreaded Batch Inference took: 3.948028898999837 seconds.\n",
            "INFO:vertexai.preview.evaluation._evaluation:Computing metrics with a total of 6 Vertex Gen AI Evaluation Service API requests.\n",
            "100%|██████████| 6/6 [00:12<00:00,  2.08s/it]\n",
            "INFO:vertexai.preview.evaluation._evaluation:All 6 metric requests are successfully computed.\n",
            "INFO:vertexai.preview.evaluation._evaluation:Evaluation Took:12.47685723199993 seconds\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        \n",
              "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
              "    <style>\n",
              "      .view-vertex-resource,\n",
              "      .view-vertex-resource:hover,\n",
              "      .view-vertex-resource:visited {\n",
              "        position: relative;\n",
              "        display: inline-flex;\n",
              "        flex-direction: row;\n",
              "        height: 32px;\n",
              "        padding: 0 12px;\n",
              "          margin: 4px 18px;\n",
              "        gap: 4px;\n",
              "        border-radius: 4px;\n",
              "\n",
              "        align-items: center;\n",
              "        justify-content: center;\n",
              "        background-color: rgb(255, 255, 255);\n",
              "        color: rgb(51, 103, 214);\n",
              "\n",
              "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
              "        font-size: 13px;\n",
              "        font-weight: 500;\n",
              "        text-transform: uppercase;\n",
              "        text-decoration: none !important;\n",
              "\n",
              "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
              "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
              "      }\n",
              "      .view-vertex-resource:active {\n",
              "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
              "      }\n",
              "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
              "        position: absolute;\n",
              "        top: 0;\n",
              "        bottom: 0;\n",
              "        left: 0;\n",
              "        right: 0;\n",
              "        border-radius: 4px;\n",
              "        pointer-events: none;\n",
              "\n",
              "        content: '';\n",
              "        background-color: rgb(51, 103, 214);\n",
              "        opacity: 0.12;\n",
              "      }\n",
              "      .view-vertex-icon {\n",
              "        font-size: 18px;\n",
              "      }\n",
              "    </style>\n",
              "  \n",
              "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-af84a518-b94e-4cf0-b306-090b9d186e1e\" href=\"#view-view-vertex-resource-af84a518-b94e-4cf0-b306-090b9d186e1e\">\n",
              "          <span class=\"material-icons view-vertex-icon\">bar_chart</span>\n",
              "          <span>View evaluation results</span>\n",
              "        </a>\n",
              "        \n",
              "        <script>\n",
              "          (function () {\n",
              "            const link = document.getElementById('view-vertex-resource-af84a518-b94e-4cf0-b306-090b9d186e1e');\n",
              "            link.addEventListener('click', (e) => {\n",
              "              if (window.google?.colab?.openUrl) {\n",
              "                window.google.colab.openUrl('https://cloud.google.com/vertex-ai/generative-ai/docs/models/view-evaluation');\n",
              "              } else {\n",
              "                window.open('https://cloud.google.com/vertex-ai/generative-ai/docs/models/view-evaluation', '_blank');\n",
              "              }\n",
              "              e.stopPropagation();\n",
              "              e.preventDefault();\n",
              "            });\n",
              "          })();\n",
              "        </script>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "PROMPT COMPARISON RESULTS\n",
            "============================================================\n",
            "Metric          Zero-Shot       Few-Shot       \n",
            "------------------------------------------------------------\n",
            "rouge_l         0.1194           0.5125*\n",
            "coherence       5.0000           5.0000\n",
            "============================================================\n",
            "Evaluation Complete.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "BosskV2.2_Testing_&_Eval"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
